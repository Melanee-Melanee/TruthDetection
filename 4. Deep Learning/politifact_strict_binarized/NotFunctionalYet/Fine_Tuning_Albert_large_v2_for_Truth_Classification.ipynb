{"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6736,"status":"ok","timestamp":1617551149925,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"1hkhc10wNrGt","outputId":"c8efce7c-93d7-4609-e050-129f4a2680c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==3.0.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\r\u001b[K     |▍                               | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 14.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 7.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/59/68c7e3833f535615fb97d33ffcb7b30bbf62bc7477a9c59cd19ad8535d72/tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 10.0MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n","\u001b[K     |████████████████████████████████| 870kB 34.8MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 50.4MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-\u003etransformers==3.0.2) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==3.0.2) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==3.0.2) (3.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==3.0.2) (2020.12.5)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers==3.0.2) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-\u003etransformers==3.0.2) (1.0.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=c4ca762017669af00b6c50f4682ed0b4eb4b64cc0dc5d527acde9cb0158ec5ee\n","  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.44 sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n"]}],"source":["!pip install transformers==3.0.2"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":12343,"status":"ok","timestamp":1617551155537,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"x4giRzM7NtHJ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast, AlbertTokenizer\n","\n","# specify GPU\n","device = torch.device(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"kKd-Tj3hOMsZ"},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147720,"status":"ok","timestamp":1617551290931,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"YyOhkwUbPeyN","outputId":"b8f1d197-3e49-4e40-fff9-4172e263556c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":148669,"status":"ok","timestamp":1617551291884,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"txbiKJKkWavQ"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":149018,"status":"ok","timestamp":1617551292367,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"BVxic54_PfFw","outputId":"3289f96c-a9bc-4595-9303-640fd8250e7d"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003estatement\u003c/th\u003e\n","      \u003cth\u003esource\u003c/th\u003e\n","      \u003cth\u003elink\u003c/th\u003e\n","      \u003cth\u003everacity\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eSen. Kamala Harris is \"supporting the animals ...\u003c/td\u003e\n","      \u003ctd\u003eDonald Trump\u003c/td\u003e\n","      \u003ctd\u003e/web/20180705082623/https://www.politifact.com...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eSays Ronald Reagan said immigrants \"brought wi...\u003c/td\u003e\n","      \u003ctd\u003eBecoming American Initiative\u003c/td\u003e\n","      \u003ctd\u003e/web/20180705082623/https://www.politifact.com...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eSays Democratic Senators \"demand Supreme Court...\u003c/td\u003e\n","      \u003ctd\u003eViral image\u003c/td\u003e\n","      \u003ctd\u003e/web/20180705082623/https://www.politifact.com...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e\"Tim Kaine doesn’t want a border at all. He wa...\u003c/td\u003e\n","      \u003ctd\u003eCorey  Stewart\u003c/td\u003e\n","      \u003ctd\u003e/web/20180705082623/https://www.politifact.com...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e\"George H.W. Bush has died at 94.\"\u003c/td\u003e\n","      \u003ctd\u003eBloggers\u003c/td\u003e\n","      \u003ctd\u003e/web/20180705082623/https://www.politifact.com...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["                                           statement  ... veracity\n","0  Sen. Kamala Harris is \"supporting the animals ...  ...        0\n","1  Says Ronald Reagan said immigrants \"brought wi...  ...        1\n","2  Says Democratic Senators \"demand Supreme Court...  ...        0\n","3  \"Tim Kaine doesn’t want a border at all. He wa...  ...        0\n","4                 \"George H.W. Bush has died at 94.\"  ...        0\n","\n","[5 rows x 4 columns]"]},"execution_count":4,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df=pd.read_csv('gdrive/My Drive/Licenta/Data/politifact_clean_binarized.csv')\n","# df=pd.read_csv('gdrive/My Drive/Licenta/Data/mafiascum_label_text.csv')\n","# df=pd.read_csv('gdrive/My Drive/Licenta/Data/mafiascum_label_words.csv')\n","df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148988,"status":"ok","timestamp":1617551292369,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"WAcp4f4PPDtW","outputId":"acdbe82f-0153-4428-bd83-8e2ec2f5098d"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                            statement  ... veracity\n","0   Sen. Kamala Harris is \"supporting the animals ...  ...        0\n","1   Says Ronald Reagan said immigrants \"brought wi...  ...        1\n","2   Says Democratic Senators \"demand Supreme Court...  ...        0\n","3   \"Tim Kaine doesn’t want a border at all. He wa...  ...        0\n","4                  \"George H.W. Bush has died at 94.\"  ...        0\n","5   \"The deficit ... is coming down, and it’s comi...  ...        0\n","6   \"Watch those GDP numbers. We started off at a ...  ...        0\n","7   \"The European Union … they send us Mercedes, t...  ...        0\n","8   \"Clinton campaign official arrested by FBI on ...  ...        0\n","9   \"Our courts find that 80 percent of those who ...  ...        0\n","10  Says a progressive income tax proposal from De...  ...        0\n","11  Says Wisconsin \"hadn’t been won by a Republica...  ...        0\n","12     \"Maxine Waters Is Getting Criminally Charged!\"  ...        0\n","13  Says Ron DeSantis \"voted in an agricultural bi...  ...        0\n","14  Says Adam Putnam \"endorsed the Schumer-Obama G...  ...        1\n","15  \"There isn't a system\" for reuniting families ...  ...        1\n","16  Say \"Dunkin' Donuts is providing a free Ḍozen ...  ...        0\n","17  \"Burka clad woman runs over baby, gets away wi...  ...        0\n","18  \"NASA announced that it communicated with four...  ...        0\n","19  \"Mexico’s Next President Calls for An Invasion...  ...        0\n","20  \"Migrant mother and ‘crying girl’ on Time cove...  ...        1\n","21  Says Republican gubernatorial candidate Adam L...  ...        0\n","22  \"Obama administration kept illegal Mexican kid...  ...        0\n","23  \"Fact: Over 90,000 kids were detained under Ob...  ...        0\n","24  \"$1 billion—that’s how much Bruce Rauner has w...  ...        0\n","25  Says Donald Trump's executive order \"doesn't a...  ...        1\n","26  A Chinese proverb says, \"Those who say it can ...  ...        0\n","27  \"Since taking office, we have enacted more tha...  ...        1\n","28  \"Bill Clinton passed a law in 1996 that separa...  ...        0\n","29  \"Busted: Obama is holding secret meetings to o...  ...        0\n","30  \"There's been a 1,700 percent increase in asyl...  ...        1\n","31  \"Under Emanuel, CPS has become the most unders...  ...        1\n","32  Says May 2018 marked the 401st straight month ...  ...        1\n","33  States with voter ID laws have seen \"zero decr...  ...        0\n","34  Says Sen. Tim Kaine \"approves of and even appl...  ...        0\n","35     \"39% of All California Students are illegals.\"  ...        0\n","36  \"More than 66% of ALL births in California are...  ...        0\n","37  \"By law, Democrats gave the superintendent of ...  ...        0\n","38  Says Sen. Bill Nelson \"voted for higher taxes\"...  ...        0\n","39  Sen. Kamala Harris is \"supporting the animals ...  ...        0\n","40  Says Ronald Reagan said immigrants \"brought wi...  ...        1\n","41  Says Democratic Senators \"demand Supreme Court...  ...        0\n","42  \"Tim Kaine doesn’t want a border at all. He wa...  ...        0\n","43                 \"George H.W. Bush has died at 94.\"  ...        0\n","44  \"The deficit ... is coming down, and it’s comi...  ...        0\n","45  \"Watch those GDP numbers. We started off at a ...  ...        0\n","46  \"The European Union … they send us Mercedes, t...  ...        0\n","47  \"Clinton campaign official arrested by FBI on ...  ...        0\n","48  \"Our courts find that 80 percent of those who ...  ...        0\n","49  Says a progressive income tax proposal from De...  ...        0\n","\n","[50 rows x 4 columns]\n"]}],"source":["print(df[:50])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148965,"status":"ok","timestamp":1617551292372,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"fzPPOrVQWiW5","outputId":"599ff26c-5bc5-4f09-80ad-b76819d983fc"},"outputs":[{"data":{"text/plain":["(11188, 4)"]},"execution_count":6,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":148949,"status":"ok","timestamp":1617551292373,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"676DPU1BOPdp","outputId":"c2313f71-a6d5-4359-bc2a-2852aedfc56f"},"outputs":[{"data":{"text/plain":["0    0.566232\n","1    0.433768\n","Name: veracity, dtype: float64"]},"execution_count":7,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["# check class distribution\n","df['veracity'].value_counts(normalize = True)"]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":148947,"status":"ok","timestamp":1617551292374,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"mfhSPF5jOWb7"},"outputs":[],"source":["train_text, temp_text, train_labels, temp_labels = train_test_split(df['statement'], df['veracity'], \n","                                                                    random_state=2018, \n","                                                                    test_size=0.3, \n","                                                                    stratify=df['veracity'])\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","                                                                random_state=2018, \n","                                                                test_size=0.5, \n","                                                                stratify=temp_labels)"]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"elapsed":152331,"status":"ok","timestamp":1617551295777,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"S1kY3gZjO2RE","outputId":"5d22c718-a02f-41b8-dae9-243a69590c29"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d48ba6d37f34aaeb1acb6d70f4db423","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=685.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7e25353cb0d4936b1404a4725629d30","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=71509304.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7083435b7c44b91a47bb4f893d518fe","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["# import BERT-base pretrained model\n","bert = AutoModel.from_pretrained('albert-large-v2')\n","\n","# Load the BERT tokenizer\n","tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":152327,"status":"ok","timestamp":1617551295778,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"_zOKeOMeO-DT"},"outputs":[],"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152311,"status":"ok","timestamp":1617551295779,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"oAH73n39PHLw","outputId":"9df3e95c-63de-4c8f-8bf4-34150355b573"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[2, 48, 25, 21, 11502, 1061, 29724, 3, 0, 0, 0], [2, 95, 129, 1123, 8, 38, 6763, 21, 11502, 1061, 3]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}],"source":["# output\n","print(sent_id)"]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":153112,"status":"ok","timestamp":1617551296600,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"yKwbpeN_PMiu","outputId":"1b4b0f25-8d33-440a-92fe-53f25e9ee53d"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7f66c8e46550\u003e"]},"execution_count":12,"metadata":{"tags":[]},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["# get length of all the messages in the train set\n","seq_len = [len(i.split()) for i in train_text]\n","\n","pd.Series(seq_len).hist(bins = 30)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":153109,"status":"ok","timestamp":1617551296602,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"OXcswEIRPvGe"},"outputs":[],"source":["max_seq_len = 50"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":154404,"status":"ok","timestamp":1617551297901,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"tk5S7DWaP2t6"},"outputs":[],"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":154403,"status":"ok","timestamp":1617551297902,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"QR-lXwmzQPd6"},"outputs":[],"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":154401,"status":"ok","timestamp":1617551297904,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"qUy9JKFYQYLp"},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 48\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":154398,"status":"ok","timestamp":1617551297905,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"wHZ0MC00RQA_"},"outputs":[],"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = False"]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":154395,"status":"ok","timestamp":1617551297906,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"b3iEtGyYRd0A"},"outputs":[],"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      self.fc1 = nn.Linear(1024,512)\n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(512,2)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n","      \n","      x = self.fc1(cls_hs)\n","\n","      x = self.relu(x)\n","\n","      x = self.dropout(x)\n","\n","      # output layer\n","      x = self.fc2(x)\n","      \n","      # apply softmax activation\n","      x = self.softmax(x)\n","\n","      return x"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":164615,"status":"ok","timestamp":1617551308128,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"cBAJJVuJRliv"},"outputs":[],"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":164613,"status":"ok","timestamp":1617551308129,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"taXS0IilRn9J"},"outputs":[],"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 4e-5)"]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164595,"status":"ok","timestamp":1617551308129,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"izY5xH5eR7Ur","outputId":"fde03d36-4a9f-407a-ad73-5b947b2347df"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.8830627  1.15263468]\n"]}],"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","\n","print(class_wts)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":164593,"status":"ok","timestamp":1617551308130,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"r1WvfY2vSGKi"},"outputs":[],"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 30"]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":164592,"status":"ok","timestamp":1617551308130,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"rskLk8R_SahS"},"outputs":[],"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:\u003e5,}  of  {:\u003e5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":164589,"status":"ok","timestamp":1617551308131,"user":{"displayName":"Sergiu C","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhfqiW02ba2m04oUe7wNwz56AyLNmv59N1G4krbHIc=s64","userId":"11087898073562528768"},"user_tz":-180},"id":"yGXovFDlSxB5"},"outputs":[],"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      # elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:\u003e5,}  of  {:\u003e5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"k1USGTntS3TS"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Epoch 1 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.691\n","Validation Loss: 0.694\n","\n"," Epoch 2 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.687\n","Validation Loss: 0.683\n","\n"," Epoch 3 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.684\n","Validation Loss: 0.678\n","\n"," Epoch 4 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.683\n","Validation Loss: 0.678\n","\n"," Epoch 5 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.682\n","Validation Loss: 0.678\n","\n"," Epoch 6 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.681\n","Validation Loss: 0.678\n","\n"," Epoch 7 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.679\n","Validation Loss: 0.676\n","\n"," Epoch 8 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.680\n","Validation Loss: 0.675\n","\n"," Epoch 9 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.678\n","Validation Loss: 0.677\n","\n"," Epoch 10 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.674\n","Validation Loss: 0.674\n","\n"," Epoch 11 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.673\n","Validation Loss: 0.672\n","\n"," Epoch 12 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.676\n","Validation Loss: 0.680\n","\n"," Epoch 13 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.673\n","Validation Loss: 0.677\n","\n"," Epoch 14 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.673\n","Validation Loss: 0.679\n","\n"," Epoch 15 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.671\n","Validation Loss: 0.670\n","\n"," Epoch 16 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.670\n","Validation Loss: 0.672\n","\n"," Epoch 17 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.670\n","Validation Loss: 0.676\n","\n"," Epoch 18 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.672\n","Validation Loss: 0.670\n","\n"," Epoch 19 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.670\n","Validation Loss: 0.681\n","\n"," Epoch 20 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.669\n","Validation Loss: 0.679\n","\n"," Epoch 21 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.671\n","Validation Loss: 0.670\n","\n"," Epoch 22 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.670\n","Validation Loss: 0.669\n","\n"," Epoch 23 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.665\n","Validation Loss: 0.679\n","\n"," Epoch 24 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.668\n","Validation Loss: 0.667\n","\n"," Epoch 25 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.665\n","Validation Loss: 0.668\n","\n"," Epoch 26 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.665\n","Validation Loss: 0.669\n","\n"," Epoch 27 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.667\n","Validation Loss: 0.667\n","\n"," Epoch 28 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.668\n","Validation Loss: 0.669\n","\n"," Epoch 29 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.669\n","Validation Loss: 0.686\n","\n"," Epoch 30 / 30\n","  Batch    50  of    164.\n","  Batch   100  of    164.\n","  Batch   150  of    164.\n","\n","Evaluating...\n","\n","Training Loss: 0.668\n","Validation Loss: 0.668\n"]}],"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss \u003c best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OacxUyizS8d1"},"outputs":[{"data":{"text/plain":["\u003cAll keys matched successfully\u003e"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NZl0SZmFTRQA"},"outputs":[{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-27-3a253e0de617\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-18-bba980e3a2e4\u003e\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 28\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 563\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         )\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 346\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             )\n\u001b[1;32m    348\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_group_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 299\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 279\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_layer_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mgelu_new\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \"\"\"\n\u001b[0;32m---\u003e 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.28 GiB (GPU 0; 7.43 GiB total capacity; 4.60 GiB already allocated; 194.81 MiB free; 6.54 GiB reserved in total by PyTorch)"]}],"source":["# get predictions for test data\n","with torch.no_grad():\n","  preds = model(test_seq.to(device), test_mask.to(device))\n","  preds = preds.detach().cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ms1ObHZxTYSI"},"outputs":[],"source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YqzLS7rHTp4T"},"outputs":[],"source":["# confusion matrix\n","pd.crosstab(test_y, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"fhrAbAXWd0_s"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"Fine_Tuning_Albert_large_v2_for_Truth_Classification.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0dfe4916ff7a4f81ac05c48e05f57bab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6e92924bb184607a5640d6e353a2200","placeholder":"​","style":"IPY_MODEL_117cf58f1a5a46df94464c3dcd4c6014","value":" 71.5M/71.5M [00:02\u0026lt;00:00, 26.2MB/s]"}},"117cf58f1a5a46df94464c3dcd4c6014":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d48ba6d37f34aaeb1acb6d70f4db423":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cedda248b6be4f72b55faf015790882c","IPY_MODEL_8d49c972c65a465a92436c33a5e46784"],"layout":"IPY_MODEL_c51cf48c4dc245c5b52b6c34d81ef718"}},"69765ad8dec24502af2cfc3dd63175af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_9ce0b26b3d454beebe3453679bf82230","max":71509304,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8262789b77240baa31fd2f1505b66ba","value":71509304}},"6f5a5f92a4ba4388a5eb8e6c3a8b4273":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_f07eac2159db481a840adf07c78196fe","max":760289,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a54fa57d7cb42a3b65ff1099a67c90c","value":760289}},"89210d7b458b437bbf6e63e3b15c079e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a54fa57d7cb42a3b65ff1099a67c90c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"8b0cf535d0ae46f1bfa6deec706b8ffc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d49c972c65a465a92436c33a5e46784":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89210d7b458b437bbf6e63e3b15c079e","placeholder":"​","style":"IPY_MODEL_bcffb4be4455434fb40eb74e72cc0902","value":" 685/685 [00:03\u0026lt;00:00, 200B/s]"}},"91b971d366e440a08f78ae05789c6fbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ce0b26b3d454beebe3453679bf82230":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7e25353cb0d4936b1404a4725629d30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69765ad8dec24502af2cfc3dd63175af","IPY_MODEL_0dfe4916ff7a4f81ac05c48e05f57bab"],"layout":"IPY_MODEL_91b971d366e440a08f78ae05789c6fbd"}},"ab5a196c01aa4f41afcb090d7e4576dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5bf20cc8ae444b0901790e39a329103":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e24657b020d0415294381277f87e7a03","placeholder":"​","style":"IPY_MODEL_ab5a196c01aa4f41afcb090d7e4576dd","value":" 760k/760k [00:00\u0026lt;00:00, 2.46MB/s]"}},"bcffb4be4455434fb40eb74e72cc0902":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c51cf48c4dc245c5b52b6c34d81ef718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c94a81dd80d54858955e28b5484ffe00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"cedda248b6be4f72b55faf015790882c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_dabc2adc1e1d4dcea2624cc776ebb54a","max":685,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c94a81dd80d54858955e28b5484ffe00","value":685}},"dabc2adc1e1d4dcea2624cc776ebb54a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e24657b020d0415294381277f87e7a03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6e92924bb184607a5640d6e353a2200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f07eac2159db481a840adf07c78196fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7083435b7c44b91a47bb4f893d518fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f5a5f92a4ba4388a5eb8e6c3a8b4273","IPY_MODEL_b5bf20cc8ae444b0901790e39a329103"],"layout":"IPY_MODEL_8b0cf535d0ae46f1bfa6deec706b8ffc"}},"f8262789b77240baa31fd2f1505b66ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}}}}},"nbformat":4,"nbformat_minor":0}